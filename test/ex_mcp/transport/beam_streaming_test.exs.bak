defmodule ExMCP.Transport.BeamStreamingTest do
  @moduledoc """
  Comprehensive tests for BEAM transport streaming support.
  
  Tests streaming capabilities for handling large payloads:
  - Stream-based message delivery
  - Backpressure handling and flow control
  - Chunked transfer for resources
  - Memory-efficient processing
  """
  use ExUnit.Case, async: true
  
  alias ExMCP.Transport.Beam
  alias ExMCP.Transport.Beam.{Stream, StreamChunk, Connection}
  
  describe "stream initialization" do
    test "creates stream with unique ID and metadata" do
      stream_opts = %{
        content_type: "application/json",
        total_size: 1024,
        chunk_size: 256
      }
      
      {:ok, stream} = Beam.Stream.new(stream_opts)
      
      assert is_binary(stream.id)
      assert byte_size(stream.id) == 32  # UUID without hyphens
      assert stream.content_type == "application/json"
      assert stream.total_size == 1024
      assert stream.chunk_size == 256
      assert stream.status == :initialized
    end
    
    test "validates stream options" do
      # Missing required fields
      assert {:error, :missing_content_type} = Beam.Stream.new(%{})
      
      # Invalid chunk size
      invalid_opts = %{
        content_type: "text/plain",
        chunk_size: 0
      }
      assert {:error, :invalid_chunk_size} = Beam.Stream.new(invalid_opts)
    end
    
    test "generates unique stream IDs" do
      {:ok, stream1} = Beam.Stream.new(%{content_type: "text/plain"})
      {:ok, stream2} = Beam.Stream.new(%{content_type: "text/plain"})
      
      assert stream1.id != stream2.id
    end
  end
  
  describe "chunk creation and validation" do
    test "creates valid chunks with sequence numbers" do
      {:ok, stream} = Beam.Stream.new(%{content_type: "text/plain", chunk_size: 10})
      
      data = "Hello, World!"
      {:ok, chunk} = StreamChunk.new(stream.id, 1, data, false)
      
      assert chunk.stream_id == stream.id
      assert chunk.sequence == 1
      assert chunk.data == "Hello, World!"
      assert chunk.is_final == false
      assert is_integer(chunk.timestamp)
    end
    
    test "validates chunk data size" do
      {:ok, stream} = Beam.Stream.new(%{content_type: "text/plain", chunk_size: 5})
      
      # Chunk too large
      large_data = "This is too large for the chunk size"
      assert {:error, :chunk_too_large} = StreamChunk.new(stream.id, 1, large_data, false)
      
      # Valid chunk
      small_data = "Hello"
      assert {:ok, _chunk} = StreamChunk.new(stream.id, 1, small_data, false)
    end
    
    test "creates final chunks" do
      {:ok, stream} = Beam.Stream.new(%{content_type: "text/plain"})
      
      {:ok, chunk} = StreamChunk.new(stream.id, 5, "Final data", true)
      
      assert chunk.is_final == true
      assert chunk.sequence == 5
    end
  end
  
  describe "streaming large tool outputs" do
    test "streams large JSON responses in chunks" do
      # Simulate a large tool output (e.g., database query result)
      large_data = generate_large_json_data(10_000)  # 10KB of JSON
      
      stream_opts = %{
        content_type: "application/json",
        total_size: byte_size(large_data),
        chunk_size: 1024  # 1KB chunks
      }
      
      {:ok, stream} = Beam.Stream.new(stream_opts)
      {:ok, chunks} = Beam.Stream.chunk_data(stream, large_data)
      
      # Should create multiple chunks
      assert length(chunks) > 1
      assert length(chunks) <= 11  # ~10KB / 1KB + 1 for remainder
      
      # Verify chunk sequence and final flag
      chunks
      |> Enum.with_index(1)
      |> Enum.each(fn {chunk, index} ->
        assert chunk.sequence == index
        
        if index == length(chunks) do
          assert chunk.is_final == true
        else
          assert chunk.is_final == false
        end
      end)
      
      # Verify data integrity when reassembled
      reassembled = chunks |> Enum.map(& &1.data) |> Enum.join()
      assert reassembled == large_data
    end
    
    test "handles binary data streaming" do
      # Simulate streaming an image or file
      binary_data = :crypto.strong_rand_bytes(5000)  # 5KB binary
      
      stream_opts = %{
        content_type: "application/octet-stream",
        total_size: byte_size(binary_data),
        chunk_size: 512
      }
      
      {:ok, stream} = Beam.Stream.new(stream_opts)
      {:ok, chunks} = Beam.Stream.chunk_data(stream, binary_data)
      
      # Verify binary integrity
      reassembled = chunks |> Enum.map(& &1.data) |> Enum.join()
      assert reassembled == binary_data
      
      # Verify all chunks are properly sized (except possibly the last)
      {initial_chunks, [final_chunk]} = Enum.split(chunks, -1)
      
      Enum.each(initial_chunks, fn chunk ->
        assert byte_size(chunk.data) == 512
        assert chunk.is_final == false
      end)
      
      assert final_chunk.is_final == true
      assert byte_size(final_chunk.data) <= 512
    end
  end
  
  describe "backpressure and flow control" do
    test "implements send window for flow control" do
      {:ok, stream} = Beam.Stream.new(%{
        content_type: "text/plain",
        chunk_size: 100,
        window_size: 3  # Allow 3 unacknowledged chunks
      })
      
      # Send initial chunks up to window size
      {:ok, window_state} = Beam.Stream.send_chunks_with_backpressure(stream, "a" |> String.duplicate(300))
      
      assert window_state.sent_count == 3
      assert window_state.acked_count == 0
      assert window_state.window_available == 0  # Window is full
    end
    
    test "handles acknowledgments and window updates" do
      {:ok, stream} = Beam.Stream.new(%{
        content_type: "text/plain", 
        chunk_size: 100,
        window_size: 2
      })
      
      # Send initial chunks
      {:ok, window_state} = Beam.Stream.send_chunks_with_backpressure(stream, "a" |> String.duplicate(200))
      
      # Acknowledge first chunk
      {:ok, updated_state} = Beam.Stream.acknowledge_chunk(window_state, 1)
      
      assert updated_state.acked_count == 1
      assert updated_state.window_available == 1  # One slot available
    end
    
    test "blocks sending when window is full" do
      {:ok, stream} = Beam.Stream.new(%{
        content_type: "text/plain",
        chunk_size: 50,
        window_size: 1  # Very small window
      })
      
      large_data = "x" |> String.duplicate(200)  # 4 chunks needed
      
      # Should block after first chunk
      result = Beam.Stream.send_chunks_with_backpressure(stream, large_data)
      
      assert {:blocked, partial_state} = result
      assert partial_state.sent_count == 1
      assert partial_state.pending_data != nil
    end
  end
  
  describe "resource streaming" do
    test "streams large resource content" do
      # Simulate streaming a large configuration file
      large_config = generate_large_config_data(8192)  # 8KB config
      
      resource_stream_opts = %{
        content_type: "application/yaml",
        resource_uri: "config://app/settings.yaml",
        total_size: byte_size(large_config),
        chunk_size: 1024
      }
      
      {:ok, stream} = Beam.Stream.new_resource_stream(resource_stream_opts)
      {:ok, chunks} = Beam.Stream.chunk_data(stream, large_config)
      
      # Verify resource-specific metadata
      assert stream.resource_uri == "config://app/settings.yaml"
      assert stream.content_type == "application/yaml"
      
      # Verify streaming
      assert length(chunks) == 8  # 8KB / 1KB
      
      # Each chunk should have resource context
      Enum.each(chunks, fn chunk ->
        assert chunk.stream_id == stream.id
        assert chunk.resource_uri == "config://app/settings.yaml"
      end)
    end
    
    test "handles streaming errors gracefully" do
      {:ok, stream} = Beam.Stream.new_resource_stream(%{
        content_type: "text/plain",
        resource_uri: "file://nonexistent.txt"
      })
      
      # Simulate resource read error
      error_result = Beam.Stream.handle_stream_error(stream, :resource_not_found)
      
      assert {:error, :resource_not_found, error_chunk} = error_result
      assert error_chunk.stream_id == stream.id
      assert error_chunk.is_final == true
      assert error_chunk.error_type == :resource_not_found
    end
  end
  
  describe "memory management" do
    test "limits concurrent streams per connection" do
      max_streams = 5
      
      # Create connection with stream limit
      {:ok, connection} = Connection.new(%{max_concurrent_streams: max_streams})
      
      # Create streams up to limit
      streams = for _i <- 1..max_streams do
        {:ok, stream} = Connection.create_stream(connection, %{content_type: "text/plain"})
        stream
      end
      
      assert length(streams) == max_streams
      
      # Attempt to create one more stream (should fail)
      assert {:error, :max_streams_exceeded} = 
        Connection.create_stream(connection, %{content_type: "text/plain"})
    end
    
    test "cleans up completed streams" do
      {:ok, connection} = Connection.new(%{max_concurrent_streams: 2})
      
      # Create and complete a stream
      {:ok, stream} = Connection.create_stream(connection, %{content_type: "text/plain"})
      {:ok, _updated_connection} = Connection.complete_stream(connection, stream.id)
      
      # Should be able to create new streams after cleanup
      {:ok, _new_stream} = Connection.create_stream(connection, %{content_type: "text/plain"})
    end
    
    test "implements stream timeout and cleanup" do
      {:ok, stream} = Stream.new(%{
        content_type: "text/plain",
        timeout_ms: 100  # Very short timeout for testing
      })
      
      # Wait for timeout
      Process.sleep(150)
      
      # Stream should be marked as timed out
      assert {:error, :stream_timeout} = Stream.check_status(stream)
    end
  end
  
  describe "integration with BEAM transport" do
    test "sends streaming messages through BEAM transport" do
      # Start a server that supports streaming
      {:ok, server} = start_streaming_server()
      
      # Connect client with streaming support
      {:ok, client} = Beam.connect([
        server: server,
        streaming: %{
          enabled: true,
          chunk_size: 512,
          window_size: 3
        }
      ])
      
      # Call a tool that returns large content
      large_tool_request = %{
        "method" => "tools/call",
        "params" => %{
          "name" => "generate_large_data",
          "arguments" => %{"size" => 5000}
        }
      }
      
      # Should receive streamed response
      {:ok, response, _state} = Beam.send_message(large_tool_request, client)
      
      assert response["streaming"] == true
      assert is_binary(response["stream_id"])
      
      # Receive stream chunks
      chunks = receive_all_chunks(client, response["stream_id"])
      
      assert length(chunks) > 1
      assert Enum.any?(chunks, & &1.is_final)
    end
    
    test "handles streaming with backpressure" do
      {:ok, server} = start_streaming_server()
      
      # Connect with very small window for testing backpressure
      {:ok, client} = Beam.connect([
        server: server,
        streaming: %{
          enabled: true,
          chunk_size: 100,
          window_size: 1  # Force backpressure
        }
      ])
      
      large_request = %{
        "method" => "tools/call",
        "params" => %{
          "name" => "generate_large_data", 
          "arguments" => %{"size" => 1000}  # 10 chunks with size 100
        }
      }
      
      {:ok, response, _state} = Beam.send_message(large_request, client)
      
      # Should receive chunks one at a time due to backpressure
      chunks = receive_chunks_with_acks(client, response["stream_id"])
      
      # Verify chunks were received in order
      sequences = Enum.map(chunks, & &1.sequence)
      assert sequences == Enum.to_list(1..length(chunks))
    end
  end
  
  # Helper functions
  
  defp generate_large_json_data(approximate_size) do
    # Generate a large JSON object for testing
    num_items = div(approximate_size, 50)  # Estimate ~50 bytes per item
    
    items = for i <- 1..num_items do
      %{
        "id" => i,
        "name" => "Item #{i}",
        "description" => "A test item with some data",
        "value" => :rand.uniform(1000)
      }
    end
    
    Jason.encode!(%{"items" => items, "total" => num_items})
  end
  
  defp generate_large_config_data(size) do
    # Generate YAML-like configuration data
    lines = for i <- 1..(div(size, 30)) do
      "setting_#{i}: value_#{i}_with_some_data"
    end
    
    Enum.join(lines, "\n")
  end
  
  defp start_streaming_server do
    # Implementation would start a test server with streaming support
    # For now, return a mock reference
    {:ok, make_ref()}
  end
  
  defp receive_all_chunks(_client, _stream_id) do
    # Implementation would receive all chunks for a stream
    # For now, return mock chunks
    [
      %StreamChunk{sequence: 1, data: "chunk1", is_final: false},
      %StreamChunk{sequence: 2, data: "chunk2", is_final: false},
      %StreamChunk{sequence: 3, data: "chunk3", is_final: true}
    ]
  end
  
  defp receive_chunks_with_acks(_client, _stream_id) do
    # Implementation would receive chunks and send acknowledgments
    # For now, return mock chunks
    [
      %StreamChunk{sequence: 1, data: "chunk1", is_final: false},
      %StreamChunk{sequence: 2, data: "chunk2", is_final: true}
    ]
  end
end